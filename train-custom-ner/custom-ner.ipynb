{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy -Uqqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./annotations.json', 'r') as json_file:\n",
    "  data = json.load(json_file)\n",
    "\n",
    "annot_data = data['annotations']\n",
    "train_size = int(len(annot_data) * 0.75)\n",
    "\n",
    "TRAIN_DATA = annot_data[:train_size]\n",
    "EVAL_DATA = annot_data[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON file into DocBin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_docbin(data, path):\n",
    "  nlp = spacy.blank(\"en\") \n",
    "  db = DocBin()\n",
    "\n",
    "  for text, annot in tqdm(data):\n",
    "      doc = nlp.make_doc(text)\n",
    "      ents = []\n",
    "      for start, end, label in annot[\"entities\"]:\n",
    "          span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "          if span is None:\n",
    "              print(\"Skipping entity\")\n",
    "          else:\n",
    "              ents.append(span)\n",
    "      doc.ents = ents\n",
    "      db.add(doc)\n",
    "\n",
    "  db.to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 1375.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 1331.92it/s]\n"
     ]
    }
   ],
   "source": [
    "json_to_docbin(TRAIN_DATA, \"./train.spacy\")\n",
    "json_to_docbin(EVAL_DATA, \"./dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Custom NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Downloading the base model needed to train data i.e. en_core_web_lg\n",
    "!python -m spacy download en_core_web_lg -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# Generated config file from https://spacy.io/usage/training\n",
    "# Now, run the following command to initialize the model\n",
    "\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     37.33    0.00    0.00    0.00    0.00\n",
      "  4     200        244.31   1659.76   25.60   28.07   23.53    0.26\n",
      "  9     400         29.75    470.65   35.09   43.48   29.41    0.35\n",
      " 18     600        529.58    526.26   49.66   45.68   54.41    0.50\n",
      " 27     800         27.47     43.64   48.28   45.45   51.47    0.48\n",
      " 40    1000          8.79     14.47   51.47   51.47   51.47    0.51\n",
      " 56    1200         32.41     45.22   48.72   43.18   55.88    0.49\n",
      " 76    1400         10.07     16.52   51.85   52.24   51.47    0.52\n",
      "100    1600          0.00      0.00   51.47   51.47   51.47    0.51\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "# If you don't have eval data/test data, you can use train DocBin i.e. train.spacy\n",
    "# after '--paths.dev' for model evaluation\n",
    "\n",
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Custom NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Vijay \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Shekhar Sharma\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOUNDER</span>\n",
       "</mark>\n",
       " is the CEO of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paytm.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STARTUP</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model by loading it from 'output/model-best' directory\n",
    "\n",
    "test_nlp = spacy.load('output/model-best')\n",
    "\n",
    "doc = test_nlp('Vijay Shekhar Sharma is the CEO of Paytm.')\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
